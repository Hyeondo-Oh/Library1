{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tensor([[1.0],[2.0],[3.0]])\n",
    "y_data = tensor([[2.0],[4.0],[6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1) # One in and one out\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must\n",
    "        return a Variable of output data. We can use Modules defined in the constructor\n",
    "        as well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss : 47.006385803222656\n",
      "Epoch: 1 | Loss : 20.94794464111328\n",
      "Epoch: 2 | Loss : 9.347152709960938\n",
      "Epoch: 3 | Loss : 4.182494163513184\n",
      "Epoch: 4 | Loss : 1.8830299377441406\n",
      "Epoch: 5 | Loss : 0.8590707182884216\n",
      "Epoch: 6 | Loss : 0.4029337465763092\n",
      "Epoch: 7 | Loss : 0.1995798498392105\n",
      "Epoch: 8 | Loss : 0.10876202583312988\n",
      "Epoch: 9 | Loss : 0.06804648786783218\n",
      "Epoch: 10 | Loss : 0.049638841301202774\n",
      "Epoch: 11 | Loss : 0.041166212409734726\n",
      "Epoch: 12 | Loss : 0.03712046146392822\n",
      "Epoch: 13 | Loss : 0.0350494384765625\n",
      "Epoch: 14 | Loss : 0.033861130475997925\n",
      "Epoch: 15 | Loss : 0.033069685101509094\n",
      "Epoch: 16 | Loss : 0.03245880827307701\n",
      "Epoch: 17 | Loss : 0.03193189948797226\n",
      "Epoch: 18 | Loss : 0.03144610673189163\n",
      "Epoch: 19 | Loss : 0.03098231740295887\n",
      "Epoch: 20 | Loss : 0.03053170070052147\n",
      "Epoch: 21 | Loss : 0.03009050339460373\n",
      "Epoch: 22 | Loss : 0.02965708076953888\n",
      "Epoch: 23 | Loss : 0.029230348765850067\n",
      "Epoch: 24 | Loss : 0.028810106217861176\n",
      "Epoch: 25 | Loss : 0.02839590050280094\n",
      "Epoch: 26 | Loss : 0.027987707406282425\n",
      "Epoch: 27 | Loss : 0.02758551388978958\n",
      "Epoch: 28 | Loss : 0.027189088985323906\n",
      "Epoch: 29 | Loss : 0.02679833397269249\n",
      "Epoch: 30 | Loss : 0.0264132022857666\n",
      "Epoch: 31 | Loss : 0.02603362500667572\n",
      "Epoch: 32 | Loss : 0.02565942332148552\n",
      "Epoch: 33 | Loss : 0.02529064752161503\n",
      "Epoch: 34 | Loss : 0.024927202612161636\n",
      "Epoch: 35 | Loss : 0.024569006636738777\n",
      "Epoch: 36 | Loss : 0.024215806275606155\n",
      "Epoch: 37 | Loss : 0.023867886513471603\n",
      "Epoch: 38 | Loss : 0.023524757474660873\n",
      "Epoch: 39 | Loss : 0.02318672463297844\n",
      "Epoch: 40 | Loss : 0.022853432223200798\n",
      "Epoch: 41 | Loss : 0.022525127977132797\n",
      "Epoch: 42 | Loss : 0.02220137231051922\n",
      "Epoch: 43 | Loss : 0.021882250905036926\n",
      "Epoch: 44 | Loss : 0.021567733958363533\n",
      "Epoch: 45 | Loss : 0.02125786803662777\n",
      "Epoch: 46 | Loss : 0.020952271297574043\n",
      "Epoch: 47 | Loss : 0.020651161670684814\n",
      "Epoch: 48 | Loss : 0.02035440504550934\n",
      "Epoch: 49 | Loss : 0.020061934366822243\n",
      "Epoch: 50 | Loss : 0.01977355405688286\n",
      "Epoch: 51 | Loss : 0.01948937028646469\n",
      "Epoch: 52 | Loss : 0.019209248945116997\n",
      "Epoch: 53 | Loss : 0.01893327757716179\n",
      "Epoch: 54 | Loss : 0.018661106005311012\n",
      "Epoch: 55 | Loss : 0.018392907455563545\n",
      "Epoch: 56 | Loss : 0.018128637224435806\n",
      "Epoch: 57 | Loss : 0.017868075519800186\n",
      "Epoch: 58 | Loss : 0.017611291259527206\n",
      "Epoch: 59 | Loss : 0.017358165234327316\n",
      "Epoch: 60 | Loss : 0.017108682543039322\n",
      "Epoch: 61 | Loss : 0.01686285436153412\n",
      "Epoch: 62 | Loss : 0.016620483249425888\n",
      "Epoch: 63 | Loss : 0.016381610184907913\n",
      "Epoch: 64 | Loss : 0.016146216541528702\n",
      "Epoch: 65 | Loss : 0.015914125367999077\n",
      "Epoch: 66 | Loss : 0.01568540185689926\n",
      "Epoch: 67 | Loss : 0.015460014343261719\n",
      "Epoch: 68 | Loss : 0.01523779146373272\n",
      "Epoch: 69 | Loss : 0.015018795616924763\n",
      "Epoch: 70 | Loss : 0.014803005382418633\n",
      "Epoch: 71 | Loss : 0.014590258710086346\n",
      "Epoch: 72 | Loss : 0.014380522072315216\n",
      "Epoch: 73 | Loss : 0.014173896983265877\n",
      "Epoch: 74 | Loss : 0.01397018227726221\n",
      "Epoch: 75 | Loss : 0.013769402168691158\n",
      "Epoch: 76 | Loss : 0.013571532443165779\n",
      "Epoch: 77 | Loss : 0.013376499526202679\n",
      "Epoch: 78 | Loss : 0.01318421307951212\n",
      "Epoch: 79 | Loss : 0.012994718737900257\n",
      "Epoch: 80 | Loss : 0.012807970866560936\n",
      "Epoch: 81 | Loss : 0.012623907066881657\n",
      "Epoch: 82 | Loss : 0.012442555278539658\n",
      "Epoch: 83 | Loss : 0.01226368360221386\n",
      "Epoch: 84 | Loss : 0.012087441980838776\n",
      "Epoch: 85 | Loss : 0.011913706548511982\n",
      "Epoch: 86 | Loss : 0.011742508970201015\n",
      "Epoch: 87 | Loss : 0.01157376915216446\n",
      "Epoch: 88 | Loss : 0.011407449841499329\n",
      "Epoch: 89 | Loss : 0.011243481189012527\n",
      "Epoch: 90 | Loss : 0.011081892065703869\n",
      "Epoch: 91 | Loss : 0.010922644287347794\n",
      "Epoch: 92 | Loss : 0.010765649378299713\n",
      "Epoch: 93 | Loss : 0.010610892437398434\n",
      "Epoch: 94 | Loss : 0.010458426550030708\n",
      "Epoch: 95 | Loss : 0.010308151133358479\n",
      "Epoch: 96 | Loss : 0.010159982368350029\n",
      "Epoch: 97 | Loss : 0.010013975203037262\n",
      "Epoch: 98 | Loss : 0.009870045818388462\n",
      "Epoch: 99 | Loss : 0.0097282025963068\n",
      "Epoch: 100 | Loss : 0.009588359855115414\n",
      "Epoch: 101 | Loss : 0.009450620040297508\n",
      "Epoch: 102 | Loss : 0.009314808994531631\n",
      "Epoch: 103 | Loss : 0.009180882945656776\n",
      "Epoch: 104 | Loss : 0.009048976935446262\n",
      "Epoch: 105 | Loss : 0.008918915875256062\n",
      "Epoch: 106 | Loss : 0.008790706284344196\n",
      "Epoch: 107 | Loss : 0.008664426393806934\n",
      "Epoch: 108 | Loss : 0.008539903908967972\n",
      "Epoch: 109 | Loss : 0.008417120203375816\n",
      "Epoch: 110 | Loss : 0.008296220563352108\n",
      "Epoch: 111 | Loss : 0.008176962845027447\n",
      "Epoch: 112 | Loss : 0.008059436455368996\n",
      "Epoch: 113 | Loss : 0.007943624630570412\n",
      "Epoch: 114 | Loss : 0.007829444482922554\n",
      "Epoch: 115 | Loss : 0.007716943509876728\n",
      "Epoch: 116 | Loss : 0.007606032304465771\n",
      "Epoch: 117 | Loss : 0.007496699690818787\n",
      "Epoch: 118 | Loss : 0.007388967555016279\n",
      "Epoch: 119 | Loss : 0.007282784674316645\n",
      "Epoch: 120 | Loss : 0.007178123574703932\n",
      "Epoch: 121 | Loss : 0.007075012661516666\n",
      "Epoch: 122 | Loss : 0.006973269395530224\n",
      "Epoch: 123 | Loss : 0.006873096339404583\n",
      "Epoch: 124 | Loss : 0.006774280685931444\n",
      "Epoch: 125 | Loss : 0.006676935590803623\n",
      "Epoch: 126 | Loss : 0.006581001915037632\n",
      "Epoch: 127 | Loss : 0.006486380938440561\n",
      "Epoch: 128 | Loss : 0.006393184419721365\n",
      "Epoch: 129 | Loss : 0.006301271263509989\n",
      "Epoch: 130 | Loss : 0.006210715975612402\n",
      "Epoch: 131 | Loss : 0.006121466401964426\n",
      "Epoch: 132 | Loss : 0.006033499259501696\n",
      "Epoch: 133 | Loss : 0.005946810357272625\n",
      "Epoch: 134 | Loss : 0.00586133636534214\n",
      "Epoch: 135 | Loss : 0.005777081940323114\n",
      "Epoch: 136 | Loss : 0.005694091320037842\n",
      "Epoch: 137 | Loss : 0.005612223409116268\n",
      "Epoch: 138 | Loss : 0.005531571339815855\n",
      "Epoch: 139 | Loss : 0.0054520610719919205\n",
      "Epoch: 140 | Loss : 0.005373719613999128\n",
      "Epoch: 141 | Loss : 0.005296473391354084\n",
      "Epoch: 142 | Loss : 0.005220348946750164\n",
      "Epoch: 143 | Loss : 0.005145330913364887\n",
      "Epoch: 144 | Loss : 0.005071430467069149\n",
      "Epoch: 145 | Loss : 0.004998518154025078\n",
      "Epoch: 146 | Loss : 0.004926679655909538\n",
      "Epoch: 147 | Loss : 0.004855904262512922\n",
      "Epoch: 148 | Loss : 0.004786091390997171\n",
      "Epoch: 149 | Loss : 0.004717291332781315\n",
      "Epoch: 150 | Loss : 0.004649528302252293\n",
      "Epoch: 151 | Loss : 0.004582692869007587\n",
      "Epoch: 152 | Loss : 0.004516837187111378\n",
      "Epoch: 153 | Loss : 0.004451924003660679\n",
      "Epoch: 154 | Loss : 0.004387950524687767\n",
      "Epoch: 155 | Loss : 0.004324883222579956\n",
      "Epoch: 156 | Loss : 0.004262732341885567\n",
      "Epoch: 157 | Loss : 0.00420145271345973\n",
      "Epoch: 158 | Loss : 0.004141088575124741\n",
      "Epoch: 159 | Loss : 0.004081581253558397\n",
      "Epoch: 160 | Loss : 0.004022917244583368\n",
      "Epoch: 161 | Loss : 0.003965084441006184\n",
      "Epoch: 162 | Loss : 0.003908106125891209\n",
      "Epoch: 163 | Loss : 0.00385194830596447\n",
      "Epoch: 164 | Loss : 0.003796569537371397\n",
      "Epoch: 165 | Loss : 0.003742025699466467\n",
      "Epoch: 166 | Loss : 0.003688232973217964\n",
      "Epoch: 167 | Loss : 0.003635229542851448\n",
      "Epoch: 168 | Loss : 0.00358299957588315\n",
      "Epoch: 169 | Loss : 0.003531506285071373\n",
      "Epoch: 170 | Loss : 0.0034807431511580944\n",
      "Epoch: 171 | Loss : 0.00343071180395782\n",
      "Epoch: 172 | Loss : 0.003381434828042984\n",
      "Epoch: 173 | Loss : 0.003332823049277067\n",
      "Epoch: 174 | Loss : 0.003284909762442112\n",
      "Epoch: 175 | Loss : 0.0032376975286751986\n",
      "Epoch: 176 | Loss : 0.003191188210621476\n",
      "Epoch: 177 | Loss : 0.003145325230434537\n",
      "Epoch: 178 | Loss : 0.003100121160969138\n",
      "Epoch: 179 | Loss : 0.003055575303733349\n",
      "Epoch: 180 | Loss : 0.0030116550624370575\n",
      "Epoch: 181 | Loss : 0.002968369284644723\n",
      "Epoch: 182 | Loss : 0.002925724256783724\n",
      "Epoch: 183 | Loss : 0.002883671782910824\n",
      "Epoch: 184 | Loss : 0.002842242829501629\n",
      "Epoch: 185 | Loss : 0.0028013878036290407\n",
      "Epoch: 186 | Loss : 0.002761100186035037\n",
      "Epoch: 187 | Loss : 0.0027214321307837963\n",
      "Epoch: 188 | Loss : 0.002682310063391924\n",
      "Epoch: 189 | Loss : 0.0026437730994075537\n",
      "Epoch: 190 | Loss : 0.0026057912036776543\n",
      "Epoch: 191 | Loss : 0.002568337367847562\n",
      "Epoch: 192 | Loss : 0.0025314355734735727\n",
      "Epoch: 193 | Loss : 0.002495033200830221\n",
      "Epoch: 194 | Loss : 0.0024591826368123293\n",
      "Epoch: 195 | Loss : 0.0024238377809524536\n",
      "Epoch: 196 | Loss : 0.002389016095548868\n",
      "Epoch: 197 | Loss : 0.00235468870960176\n",
      "Epoch: 198 | Loss : 0.0023208255879580975\n",
      "Epoch: 199 | Loss : 0.002287480281665921\n",
      "Epoch: 200 | Loss : 0.0022545969113707542\n",
      "Epoch: 201 | Loss : 0.0022221957333385944\n",
      "Epoch: 202 | Loss : 0.0021902548614889383\n",
      "Epoch: 203 | Loss : 0.002158793853595853\n",
      "Epoch: 204 | Loss : 0.00212775357067585\n",
      "Epoch: 205 | Loss : 0.002097177319228649\n",
      "Epoch: 206 | Loss : 0.002067029010504484\n",
      "Epoch: 207 | Loss : 0.002037340309470892\n",
      "Epoch: 208 | Loss : 0.0020080488175153732\n",
      "Epoch: 209 | Loss : 0.001979181310161948\n",
      "Epoch: 210 | Loss : 0.001950756530277431\n",
      "Epoch: 211 | Loss : 0.0019227082375437021\n",
      "Epoch: 212 | Loss : 0.0018950632074847817\n",
      "Epoch: 213 | Loss : 0.001867854269221425\n",
      "Epoch: 214 | Loss : 0.0018410019110888243\n",
      "Epoch: 215 | Loss : 0.0018145320937037468\n",
      "Epoch: 216 | Loss : 0.001788468100130558\n",
      "Epoch: 217 | Loss : 0.0017627511406317353\n",
      "Epoch: 218 | Loss : 0.0017374263843521476\n",
      "Epoch: 219 | Loss : 0.0017124366713687778\n",
      "Epoch: 220 | Loss : 0.0016878378810361028\n",
      "Epoch: 221 | Loss : 0.0016635952051728964\n",
      "Epoch: 222 | Loss : 0.001639666617847979\n",
      "Epoch: 223 | Loss : 0.0016161056701093912\n",
      "Epoch: 224 | Loss : 0.001592886634171009\n",
      "Epoch: 225 | Loss : 0.0015699970535933971\n",
      "Epoch: 226 | Loss : 0.0015474376268684864\n",
      "Epoch: 227 | Loss : 0.0015251960139721632\n",
      "Epoch: 228 | Loss : 0.0015032619703561068\n",
      "Epoch: 229 | Loss : 0.001481679268181324\n",
      "Epoch: 230 | Loss : 0.0014603680465370417\n",
      "Epoch: 231 | Loss : 0.0014393898891285062\n",
      "Epoch: 232 | Loss : 0.0014186883345246315\n",
      "Epoch: 233 | Loss : 0.0013983063399791718\n",
      "Epoch: 234 | Loss : 0.001378214336000383\n",
      "Epoch: 235 | Loss : 0.0013584026601165533\n",
      "Epoch: 236 | Loss : 0.0013388835359364748\n",
      "Epoch: 237 | Loss : 0.0013196533545851707\n",
      "Epoch: 238 | Loss : 0.0013006902299821377\n",
      "Epoch: 239 | Loss : 0.001281985081732273\n",
      "Epoch: 240 | Loss : 0.0012635497841984034\n",
      "Epoch: 241 | Loss : 0.0012454099487513304\n",
      "Epoch: 242 | Loss : 0.0012275013141334057\n",
      "Epoch: 243 | Loss : 0.0012098618317395449\n",
      "Epoch: 244 | Loss : 0.0011924864957109094\n",
      "Epoch: 245 | Loss : 0.0011753365397453308\n",
      "Epoch: 246 | Loss : 0.0011584453750401735\n",
      "Epoch: 247 | Loss : 0.0011417963542044163\n",
      "Epoch: 248 | Loss : 0.0011254004202783108\n",
      "Epoch: 249 | Loss : 0.0011092063505202532\n",
      "Epoch: 250 | Loss : 0.0010932700242847204\n",
      "Epoch: 251 | Loss : 0.0010775653645396233\n",
      "Epoch: 252 | Loss : 0.0010620653629302979\n",
      "Epoch: 253 | Loss : 0.0010468242689967155\n",
      "Epoch: 254 | Loss : 0.0010317793348804116\n",
      "Epoch: 255 | Loss : 0.0010169267188757658\n",
      "Epoch: 256 | Loss : 0.0010023217182606459\n",
      "Epoch: 257 | Loss : 0.0009879154385998845\n",
      "Epoch: 258 | Loss : 0.000973709742538631\n",
      "Epoch: 259 | Loss : 0.0009597166790626943\n",
      "Epoch: 260 | Loss : 0.0009459286811761558\n",
      "Epoch: 261 | Loss : 0.0009323345148004591\n",
      "Epoch: 262 | Loss : 0.0009189427364617586\n",
      "Epoch: 263 | Loss : 0.0009057248826138675\n",
      "Epoch: 264 | Loss : 0.0008927121525630355\n",
      "Epoch: 265 | Loss : 0.0008798781782388687\n",
      "Epoch: 266 | Loss : 0.0008672260446473956\n",
      "Epoch: 267 | Loss : 0.0008547727484256029\n",
      "Epoch: 268 | Loss : 0.0008424820262007415\n",
      "Epoch: 269 | Loss : 0.0008303791983053088\n",
      "Epoch: 270 | Loss : 0.000818452041130513\n",
      "Epoch: 271 | Loss : 0.0008066739537753165\n",
      "Epoch: 272 | Loss : 0.0007950943545438349\n",
      "Epoch: 273 | Loss : 0.0007836684817448258\n",
      "Epoch: 274 | Loss : 0.0007723963353782892\n",
      "Epoch: 275 | Loss : 0.0007612989284098148\n",
      "Epoch: 276 | Loss : 0.0007503582746721804\n",
      "Epoch: 277 | Loss : 0.0007395775173790753\n",
      "Epoch: 278 | Loss : 0.0007289485074579716\n",
      "Epoch: 279 | Loss : 0.0007184743299148977\n",
      "Epoch: 280 | Loss : 0.0007081471849232912\n",
      "Epoch: 281 | Loss : 0.0006979653262533247\n",
      "Epoch: 282 | Loss : 0.0006879442953504622\n",
      "Epoch: 283 | Loss : 0.0006780516123399138\n",
      "Epoch: 284 | Loss : 0.0006683133542537689\n",
      "Epoch: 285 | Loss : 0.0006587081006728113\n",
      "Epoch: 286 | Loss : 0.0006492302054539323\n",
      "Epoch: 287 | Loss : 0.0006399122066795826\n",
      "Epoch: 288 | Loss : 0.0006307126022875309\n",
      "Epoch: 289 | Loss : 0.0006216434994712472\n",
      "Epoch: 290 | Loss : 0.0006127162487246096\n",
      "Epoch: 291 | Loss : 0.000603899359703064\n",
      "Epoch: 292 | Loss : 0.000595228630118072\n",
      "Epoch: 293 | Loss : 0.0005866613937541842\n",
      "Epoch: 294 | Loss : 0.0005782387452200055\n",
      "Epoch: 295 | Loss : 0.0005699326284229755\n",
      "Epoch: 296 | Loss : 0.0005617375136353076\n",
      "Epoch: 297 | Loss : 0.0005536715034395456\n",
      "Epoch: 298 | Loss : 0.0005457060178741813\n",
      "Epoch: 299 | Loss : 0.000537866959348321\n",
      "Epoch: 300 | Loss : 0.0005301368073560297\n",
      "Epoch: 301 | Loss : 0.0005225198110565543\n",
      "Epoch: 302 | Loss : 0.0005150000797584653\n",
      "Epoch: 303 | Loss : 0.0005076082306914032\n",
      "Epoch: 304 | Loss : 0.0005003140540793538\n",
      "Epoch: 305 | Loss : 0.0004931282019242644\n",
      "Epoch: 306 | Loss : 0.0004860353365074843\n",
      "Epoch: 307 | Loss : 0.00047905874089337885\n",
      "Epoch: 308 | Loss : 0.00047216800157912076\n",
      "Epoch: 309 | Loss : 0.00046537606976926327\n",
      "Epoch: 310 | Loss : 0.00045869810855947435\n",
      "Epoch: 311 | Loss : 0.0004520968359429389\n",
      "Epoch: 312 | Loss : 0.00044560839887708426\n",
      "Epoch: 313 | Loss : 0.00043919376912526786\n",
      "Epoch: 314 | Loss : 0.0004328884824644774\n",
      "Epoch: 315 | Loss : 0.00042666244553402066\n",
      "Epoch: 316 | Loss : 0.00042052919161505997\n",
      "Epoch: 317 | Loss : 0.00041449128184467554\n",
      "Epoch: 318 | Loss : 0.00040853105019778013\n",
      "Epoch: 319 | Loss : 0.00040266301948577166\n",
      "Epoch: 320 | Loss : 0.00039687566459178925\n",
      "Epoch: 321 | Loss : 0.0003911669773515314\n",
      "Epoch: 322 | Loss : 0.0003855498507618904\n",
      "Epoch: 323 | Loss : 0.00038000516360625625\n",
      "Epoch: 324 | Loss : 0.0003745444701053202\n",
      "Epoch: 325 | Loss : 0.00036916800308972597\n",
      "Epoch: 326 | Loss : 0.0003638669732026756\n",
      "Epoch: 327 | Loss : 0.000358625256922096\n",
      "Epoch: 328 | Loss : 0.00035347510129213333\n",
      "Epoch: 329 | Loss : 0.00034839584259316325\n",
      "Epoch: 330 | Loss : 0.00034338567638769746\n",
      "Epoch: 331 | Loss : 0.00033845246070995927\n",
      "Epoch: 332 | Loss : 0.0003335941582918167\n",
      "Epoch: 333 | Loss : 0.0003287931904196739\n",
      "Epoch: 334 | Loss : 0.0003240678342990577\n",
      "Epoch: 335 | Loss : 0.0003194067976437509\n",
      "Epoch: 336 | Loss : 0.00031481252517551184\n",
      "Epoch: 337 | Loss : 0.0003102884511463344\n",
      "Epoch: 338 | Loss : 0.00030583469197154045\n",
      "Epoch: 339 | Loss : 0.0003014424000866711\n",
      "Epoch: 340 | Loss : 0.0002971049689222127\n",
      "Epoch: 341 | Loss : 0.0002928357571363449\n",
      "Epoch: 342 | Loss : 0.0002886369766201824\n",
      "Epoch: 343 | Loss : 0.0002844861592166126\n",
      "Epoch: 344 | Loss : 0.0002803907264024019\n",
      "Epoch: 345 | Loss : 0.00027636170852929354\n",
      "Epoch: 346 | Loss : 0.0002723935176618397\n",
      "Epoch: 347 | Loss : 0.00026847975095734\n",
      "Epoch: 348 | Loss : 0.0002646217180881649\n",
      "Epoch: 349 | Loss : 0.0002608188660815358\n",
      "Epoch: 350 | Loss : 0.00025706400629132986\n",
      "Epoch: 351 | Loss : 0.0002533771039452404\n",
      "Epoch: 352 | Loss : 0.0002497315581422299\n",
      "Epoch: 353 | Loss : 0.0002461388648953289\n",
      "Epoch: 354 | Loss : 0.00024260845384560525\n",
      "Epoch: 355 | Loss : 0.0002391223970334977\n",
      "Epoch: 356 | Loss : 0.00023568568576592952\n",
      "Epoch: 357 | Loss : 0.00023229687940329313\n",
      "Epoch: 358 | Loss : 0.00022895901929587126\n",
      "Epoch: 359 | Loss : 0.00022567063570022583\n",
      "Epoch: 360 | Loss : 0.00022242599516175687\n",
      "Epoch: 361 | Loss : 0.0002192280808230862\n",
      "Epoch: 362 | Loss : 0.00021607469534501433\n",
      "Epoch: 363 | Loss : 0.00021297723287716508\n",
      "Epoch: 364 | Loss : 0.0002099114062730223\n",
      "Epoch: 365 | Loss : 0.00020689457596745342\n",
      "Epoch: 366 | Loss : 0.00020391785074025393\n",
      "Epoch: 367 | Loss : 0.00020098660024814308\n",
      "Epoch: 368 | Loss : 0.00019810275989584625\n",
      "Epoch: 369 | Loss : 0.00019525759853422642\n",
      "Epoch: 370 | Loss : 0.000192449995665811\n",
      "Epoch: 371 | Loss : 0.00018968193035107106\n",
      "Epoch: 372 | Loss : 0.00018695698236115277\n",
      "Epoch: 373 | Loss : 0.00018426909809932113\n",
      "Epoch: 374 | Loss : 0.00018161401385441422\n",
      "Epoch: 375 | Loss : 0.00017901085084304214\n",
      "Epoch: 376 | Loss : 0.0001764388580340892\n",
      "Epoch: 377 | Loss : 0.00017390845459885895\n",
      "Epoch: 378 | Loss : 0.00017140321142505854\n",
      "Epoch: 379 | Loss : 0.0001689418131718412\n",
      "Epoch: 380 | Loss : 0.00016651097394060344\n",
      "Epoch: 381 | Loss : 0.00016411414253525436\n",
      "Epoch: 382 | Loss : 0.00016175760538317263\n",
      "Epoch: 383 | Loss : 0.00015943500329740345\n",
      "Epoch: 384 | Loss : 0.00015714450273662806\n",
      "Epoch: 385 | Loss : 0.0001548857835587114\n",
      "Epoch: 386 | Loss : 0.000152656328282319\n",
      "Epoch: 387 | Loss : 0.00015046157932374626\n",
      "Epoch: 388 | Loss : 0.00014830043073743582\n",
      "Epoch: 389 | Loss : 0.00014617179112974554\n",
      "Epoch: 390 | Loss : 0.00014407247363124043\n",
      "Epoch: 391 | Loss : 0.000141998752951622\n",
      "Epoch: 392 | Loss : 0.00013996139750815928\n",
      "Epoch: 393 | Loss : 0.00013794830010738224\n",
      "Epoch: 394 | Loss : 0.0001359606540063396\n",
      "Epoch: 395 | Loss : 0.0001340109738521278\n",
      "Epoch: 396 | Loss : 0.00013208140444476157\n",
      "Epoch: 397 | Loss : 0.00013018572644796222\n",
      "Epoch: 398 | Loss : 0.00012830967898480594\n",
      "Epoch: 399 | Loss : 0.0001264694583369419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400 | Loss : 0.0001246542378794402\n",
      "Epoch: 401 | Loss : 0.00012286051060073078\n",
      "Epoch: 402 | Loss : 0.0001210989648825489\n",
      "Epoch: 403 | Loss : 0.0001193558782688342\n",
      "Epoch: 404 | Loss : 0.00011763991642510518\n",
      "Epoch: 405 | Loss : 0.00011594953684834763\n",
      "Epoch: 406 | Loss : 0.00011428506695665419\n",
      "Epoch: 407 | Loss : 0.00011263632768532261\n",
      "Epoch: 408 | Loss : 0.00011102468124590814\n",
      "Epoch: 409 | Loss : 0.00010943133383989334\n",
      "Epoch: 410 | Loss : 0.00010785677295643836\n",
      "Epoch: 411 | Loss : 0.000106305000372231\n",
      "Epoch: 412 | Loss : 0.00010477814794285223\n",
      "Epoch: 413 | Loss : 0.00010327181371394545\n",
      "Epoch: 414 | Loss : 0.00010178341472055763\n",
      "Epoch: 415 | Loss : 0.00010032037971541286\n",
      "Epoch: 416 | Loss : 9.888181375572458e-05\n",
      "Epoch: 417 | Loss : 9.746052091941237e-05\n",
      "Epoch: 418 | Loss : 9.605921513866633e-05\n",
      "Epoch: 419 | Loss : 9.467994095757604e-05\n",
      "Epoch: 420 | Loss : 9.331961337011307e-05\n",
      "Epoch: 421 | Loss : 9.198083716910332e-05\n",
      "Epoch: 422 | Loss : 9.065728227142245e-05\n",
      "Epoch: 423 | Loss : 8.934935613069683e-05\n",
      "Epoch: 424 | Loss : 8.806894766166806e-05\n",
      "Epoch: 425 | Loss : 8.680103201186284e-05\n",
      "Epoch: 426 | Loss : 8.555466774851084e-05\n",
      "Epoch: 427 | Loss : 8.432479808107018e-05\n",
      "Epoch: 428 | Loss : 8.311284909723327e-05\n",
      "Epoch: 429 | Loss : 8.191703091142699e-05\n",
      "Epoch: 430 | Loss : 8.074189827311784e-05\n",
      "Epoch: 431 | Loss : 7.95788801042363e-05\n",
      "Epoch: 432 | Loss : 7.843923958716914e-05\n",
      "Epoch: 433 | Loss : 7.73073043092154e-05\n",
      "Epoch: 434 | Loss : 7.619628740940243e-05\n",
      "Epoch: 435 | Loss : 7.510439900215715e-05\n",
      "Epoch: 436 | Loss : 7.402389019262046e-05\n",
      "Epoch: 437 | Loss : 7.295816612895578e-05\n",
      "Epoch: 438 | Loss : 7.191149779828265e-05\n",
      "Epoch: 439 | Loss : 7.088072743499652e-05\n",
      "Epoch: 440 | Loss : 6.986031075939536e-05\n",
      "Epoch: 441 | Loss : 6.885453331051394e-05\n",
      "Epoch: 442 | Loss : 6.786561425542459e-05\n",
      "Epoch: 443 | Loss : 6.689146539429203e-05\n",
      "Epoch: 444 | Loss : 6.593285797862336e-05\n",
      "Epoch: 445 | Loss : 6.498304719571024e-05\n",
      "Epoch: 446 | Loss : 6.405175372492522e-05\n",
      "Epoch: 447 | Loss : 6.313042104011402e-05\n",
      "Epoch: 448 | Loss : 6.222218507900834e-05\n",
      "Epoch: 449 | Loss : 6.13273587077856e-05\n",
      "Epoch: 450 | Loss : 6.0445338021963835e-05\n",
      "Epoch: 451 | Loss : 5.958137262496166e-05\n",
      "Epoch: 452 | Loss : 5.8721409004647285e-05\n",
      "Epoch: 453 | Loss : 5.7879191444953904e-05\n",
      "Epoch: 454 | Loss : 5.704569412046112e-05\n",
      "Epoch: 455 | Loss : 5.622521348414011e-05\n",
      "Epoch: 456 | Loss : 5.541630889638327e-05\n",
      "Epoch: 457 | Loss : 5.462013359647244e-05\n",
      "Epoch: 458 | Loss : 5.383655661717057e-05\n",
      "Epoch: 459 | Loss : 5.306201637722552e-05\n",
      "Epoch: 460 | Loss : 5.2298571972642094e-05\n",
      "Epoch: 461 | Loss : 5.155066173756495e-05\n",
      "Epoch: 462 | Loss : 5.080772825749591e-05\n",
      "Epoch: 463 | Loss : 5.007594882044941e-05\n",
      "Epoch: 464 | Loss : 4.935560718877241e-05\n",
      "Epoch: 465 | Loss : 4.8650617827661335e-05\n",
      "Epoch: 466 | Loss : 4.7950299631338567e-05\n",
      "Epoch: 467 | Loss : 4.7259854909498245e-05\n",
      "Epoch: 468 | Loss : 4.657838508137502e-05\n",
      "Epoch: 469 | Loss : 4.591171455103904e-05\n",
      "Epoch: 470 | Loss : 4.525141412159428e-05\n",
      "Epoch: 471 | Loss : 4.459861520444974e-05\n",
      "Epoch: 472 | Loss : 4.396019721752964e-05\n",
      "Epoch: 473 | Loss : 4.333096876507625e-05\n",
      "Epoch: 474 | Loss : 4.270400677341968e-05\n",
      "Epoch: 475 | Loss : 4.209028338664211e-05\n",
      "Epoch: 476 | Loss : 4.148661901126616e-05\n",
      "Epoch: 477 | Loss : 4.0892518882174045e-05\n",
      "Epoch: 478 | Loss : 4.030233685625717e-05\n",
      "Epoch: 479 | Loss : 3.972304330090992e-05\n",
      "Epoch: 480 | Loss : 3.915303750545718e-05\n",
      "Epoch: 481 | Loss : 3.858895070152357e-05\n",
      "Epoch: 482 | Loss : 3.803541403613053e-05\n",
      "Epoch: 483 | Loss : 3.74908595404122e-05\n",
      "Epoch: 484 | Loss : 3.6949168134015054e-05\n",
      "Epoch: 485 | Loss : 3.642090086941607e-05\n",
      "Epoch: 486 | Loss : 3.589539119275287e-05\n",
      "Epoch: 487 | Loss : 3.537991869961843e-05\n",
      "Epoch: 488 | Loss : 3.4872296964749694e-05\n",
      "Epoch: 489 | Loss : 3.437141276663169e-05\n",
      "Epoch: 490 | Loss : 3.387652395758778e-05\n",
      "Epoch: 491 | Loss : 3.3386899303877726e-05\n",
      "Epoch: 492 | Loss : 3.290917811682448e-05\n",
      "Epoch: 493 | Loss : 3.2437215850222856e-05\n",
      "Epoch: 494 | Loss : 3.19719547405839e-05\n",
      "Epoch: 495 | Loss : 3.151135751977563e-05\n",
      "Epoch: 496 | Loss : 3.1058960303198546e-05\n",
      "Epoch: 497 | Loss : 3.061305687879212e-05\n",
      "Epoch: 498 | Loss : 3.0172610422596335e-05\n",
      "Epoch: 499 | Loss : 2.9737575459876098e-05\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(500):\n",
    "    # 1) Forward pass : Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # 2) Compute and print loss\n",
    "    loss = criterion(y_pred,y_data)\n",
    "    print(f'Epoch: {epoch} | Loss : {loss.item()}')\n",
    "    \n",
    "    # 3) Zero gradients, perform a backward pass, and update weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (after training) 4 7.993731498718262\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "hour_var = tensor([[4.0]])\n",
    "y_pred = model(hour_var)\n",
    "print(\"Prediction (after training)\", 4, model(hour_var).data[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
