{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6297a67b257a450d8d3bb41ae7138eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df18c6731fb4846a3d40e8e03253af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0358a0fc7d504d4daefb0cfa8b82a14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf5f40e53fb4b7cb7e79e36bbc0b114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Processing...\n",
      "\n",
      "\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.314905\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.304803\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.299929\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.303702\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.304085\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.299433\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.294686\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.299772\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.304119\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.295014\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.295266\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.294970\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.289238\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.310683\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.299308\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.298739\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.303326\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.300058\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.295166\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.299780\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.290858\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.293270\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.296328\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.296071\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.287832\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.289840\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.295992\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.293406\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.291212\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.291565\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.291249\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.286690\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.288064\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.292705\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.286941\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.292562\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.279392\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.286674\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.288538\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.283790\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.280437\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.287444\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.289364\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.274260\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.283406\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.283057\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.278823\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.278419\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.278157\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.280943\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.273927\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.267923\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.278144\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.274637\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.269275\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.267613\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.266572\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.266498\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.274814\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.256533\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.267603\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.249614\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.238841\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.258042\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.242690\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.239691\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.232509\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.252643\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.243132\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.214333\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.236659\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.223863\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.211883\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.186697\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.182490\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.172043\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.147401\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.191457\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.140637\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.152337\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.093321\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.147394\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.107573\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.058876\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.975332\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.062267\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.941498\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.855728\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.900765\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.866919\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.906954\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.753771\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.802658\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.653053\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0264, Accuracy: 5472/10000 (55%)\n",
      "Testing time: 0m 15s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.760466\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.677855\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.591515\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.623083\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.501224\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.366736\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.387657\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.241180\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.213516\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.307282\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.128710\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.134885\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.147301\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.123647\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.026598\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.952976\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.199041\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.940058\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.039252\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.890235\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.896301\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 1.000471\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.929798\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.876555\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.708208\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.940500\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.668527\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 1.156509\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.832264\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.750928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.833481\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.931903\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.652848\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.693065\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.503471\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.500127\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.790369\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.572955\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.599205\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.558704\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.358116\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.569574\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.515120\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.617122\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.498874\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.469302\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.727951\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.514233\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.548487\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.501609\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.856388\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.403613\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.456941\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.456510\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.571941\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.430083\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.728547\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.286714\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.441418\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.528690\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.415716\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.342074\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.498840\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.649129\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.489505\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.304020\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.724148\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.440202\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.514074\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.561940\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.261469\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.509125\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.310097\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.464903\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.775106\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.434175\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.467844\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.472196\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.458644\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.335538\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.319340\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.454600\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.302281\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.338221\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.489825\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.383175\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.639705\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.542406\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.275987\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.323005\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.553518\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.348187\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.464043\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.279203\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0061, Accuracy: 8860/10000 (89%)\n",
      "Testing time: 0m 15s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.560001\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.165763\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.400767\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.428923\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.515736\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.385987\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.411916\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.330252\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.236745\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.563739\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.337368\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.558829\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.465277\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.275987\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.294732\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.442014\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.366310\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.281396\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.490145\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.328821\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.632469\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.222532\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.409649\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.270315\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.378696\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.344962\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.586888\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.474104\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.285869\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.257732\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.304775\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.299246\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.691378\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.395697\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.245151\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.295212\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.317835\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.248546\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.481173\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.307541\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.432775\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.172118\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.305800\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.338861\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.604070\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.304551\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.318099\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.312675\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.235415\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.328953\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.379103\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.357605\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.271699\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.253080\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.273358\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.380270\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.097389\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.415904\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.713013\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.201527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.224330\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.288003\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.272482\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.201435\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.291414\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.390284\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.490795\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.593586\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.661809\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.408813\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.256313\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.234684\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.277429\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.293398\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.550117\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.223915\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.119908\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.269552\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.224888\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.480462\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.398031\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.590309\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.333584\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.408102\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.199738\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.382874\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.259261\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.382436\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.426889\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.475901\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.268742\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.228468\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.197532\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.317919\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0045, Accuracy: 9165/10000 (92%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.169196\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.396154\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.319325\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.213333\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.249940\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.222050\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.253670\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.461146\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.202331\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.239528\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.228108\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.281857\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.327127\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.184049\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.203264\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.134480\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.429371\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.179629\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.456009\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.424801\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.267878\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.235394\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.227990\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.289217\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.362365\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.277285\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.353771\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.190040\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.535508\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.298109\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.127139\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.239042\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.139667\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.298407\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.502793\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.109244\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.608120\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.152319\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.170912\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.109756\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.481794\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.140965\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.207410\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.219954\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.324382\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.288478\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.285692\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.407203\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.375000\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.194942\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.116660\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.350597\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.462189\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.279532\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.219502\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.143103\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.275556\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.167606\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.113677\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.205310\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.131324\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.204864\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.193645\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.104808\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.427249\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.179432\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.221749\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.151103\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.291082\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.387266\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.245202\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.326425\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.273049\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.395151\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.232836\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.310889\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.393380\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.174174\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.122396\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.282964\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.332346\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.123595\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.245505\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.179193\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.193355\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.189242\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.276125\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.184689\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.283407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.243921\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.317173\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.176655\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.097888\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.120985\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0032, Accuracy: 9405/10000 (94%)\n",
      "Testing time: 0m 17s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.216374\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.115347\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.179836\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.296286\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.283465\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.368519\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.212291\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.330488\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.201402\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.167025\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.162684\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.264191\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.131209\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.311650\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.334318\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.367264\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.133365\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.076322\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.123127\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.061705\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.053738\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.043458\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.238530\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.134386\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.304718\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.165654\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.150114\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.145496\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.288689\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.110622\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.062265\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.165311\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.396845\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.233598\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.105556\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.108813\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.386552\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.095136\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.160537\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.094037\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.184099\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.152384\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.168747\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.303869\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.187104\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.149827\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.148680\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.171982\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.224471\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.215821\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.324184\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.263794\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.107522\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.097140\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.348800\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.157075\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.156815\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.121582\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.112447\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.197466\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.195332\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.318309\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.064026\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.091631\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.272333\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.197241\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.212258\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.069383\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.105066\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.157952\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.270377\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.277581\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.219204\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.233392\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.419458\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.127050\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.142698\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.107345\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.104649\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.217867\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.174888\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.107891\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.062380\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.208705\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.137891\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.193036\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.065565\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.269664\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.070957\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.104114\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.241989\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.155444\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.217954\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.060166\n",
      "Training time: 0m 17s\n",
      "===========================\n",
      "Test set: Average loss: 0.0028, Accuracy: 9476/10000 (95%)\n",
      "Testing time: 0m 18s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.137948\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.172775\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.160550\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.133539\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.062125\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.179291\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.259722\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.097673\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.164377\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.128941\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.138375\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.207927\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.178922\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.090143\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.171047\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.232670\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.144034\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.171932\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.084071\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.163011\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.094788\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.316419\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.345560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.265685\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.183889\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.099359\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.060779\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.122155\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.210044\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.232605\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.316219\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.252011\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.130436\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.127635\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.242797\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.173274\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.180637\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.318968\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.240872\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.089010\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.144378\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.190031\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.146627\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.201163\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.223380\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.175854\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.062879\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.085506\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.262692\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.161385\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.180743\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.121251\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.071052\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.361855\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.189810\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.106447\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.364591\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.081625\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.038743\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.145639\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.103055\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.213321\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.181200\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.207755\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.196749\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.182415\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.197723\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.159194\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.032988\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.196172\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.166595\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.115602\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.121961\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.265864\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.077279\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.149886\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.112070\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.063282\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.203269\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.174720\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.198452\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.109468\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.085245\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.102707\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.253082\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.077428\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.061258\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.147232\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.105180\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.165842\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.145968\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.057984\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.093082\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.241084\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0023, Accuracy: 9560/10000 (96%)\n",
      "Testing time: 0m 17s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.216485\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.045679\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.092668\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.091332\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.098081\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.221550\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.121989\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.047957\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.324362\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.048711\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.065755\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.171609\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.023902\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.097849\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.082349\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.074997\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.078637\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.303588\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.158495\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.115904\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.066741\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.055570\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.317083\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.180544\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.075643\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.110455\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.066471\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.074888\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.210254\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.175219\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.098753\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.173271\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.102682\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.043693\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.094617\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.124329\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.095255\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.068377\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.142333\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.110377\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.066011\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.081267\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.062731\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.042489\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.165570\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.204179\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.081385\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.183331\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.109749\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.051464\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.054780\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.101190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.115928\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.079764\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.174864\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.202025\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.175278\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.063413\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.145922\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.113387\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.252735\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.086370\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.078000\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.283336\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.078681\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.050927\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.076594\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.119681\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.076354\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.120096\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.181786\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.085215\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.118475\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.142610\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.094934\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.128618\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.058689\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.158863\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.149554\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.035166\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.077006\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.181341\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.069069\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.240663\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.209290\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.175468\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.058730\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.049571\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.149938\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.057087\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.107625\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.094151\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.198772\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.111257\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0020, Accuracy: 9621/10000 (96%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.198437\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.238186\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.074165\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.041877\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.087853\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.029781\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.211543\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.041154\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.152176\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.037103\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.061171\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.072670\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.309978\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.096374\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.106399\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.060294\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.146460\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.037873\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.092390\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.058458\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.094923\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.052970\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.139270\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.114295\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.204851\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.250224\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.242077\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.053347\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.238135\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.085612\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.036390\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.071876\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.137075\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.061053\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.048709\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.086009\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.260602\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.048177\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.186504\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.049206\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.064238\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.079744\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.059866\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.046573\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.083624\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.175826\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.055393\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.109369\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.163721\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.033250\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.037923\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.134150\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.093274\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.172865\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.053609\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.163007\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.099354\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.073184\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.231315\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.192846\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.099164\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.030816\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.073687\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.114278\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.121298\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.165952\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.186679\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.067800\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.052002\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.052363\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.042035\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.120473\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.149153\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.040653\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.151021\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.068083\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.034871\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.040662\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.014575\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.122805\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.063669\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.042154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.071286\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.033531\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.217912\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.040393\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.127989\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.238333\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.089359\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.060154\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.183111\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.298853\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.167370\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.198335\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9649/10000 (96%)\n",
      "Testing time: 0m 15s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.142782\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.032116\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.031197\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.062182\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.059811\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.054799\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.133874\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.110905\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.038735\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.116152\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.048520\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.080349\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.041773\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.074897\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.050386\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.045619\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.080656\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.099720\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.158606\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.236068\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.043421\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.053102\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.078233\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.149898\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.129528\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.112093\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.047874\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.044952\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.063864\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.276191\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.057118\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.041597\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.136057\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.050893\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.031954\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.158130\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.073294\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.027918\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.062995\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.107715\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.022787\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.059008\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.071966\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.054029\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.096169\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.064261\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.098949\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.054792\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.018763\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.069006\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.049600\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.180675\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.144289\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.168468\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.035586\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.027922\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.031890\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.336809\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.124789\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.135620\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.030695\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.050582\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.100384\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.064944\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.072081\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.115582\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.085135\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.145592\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.047628\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.153248\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.119493\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.162429\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.235539\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.063593\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.172737\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.050812\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.091272\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.047221\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.108961\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.132108\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.098820\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.047218\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.058797\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.088601\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.113859\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.109638\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.099004\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.114066\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.144335\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.191649\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.017442\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.106765\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.132027\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.095720\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9662/10000 (97%)\n",
      "Testing time: 0m 16s\n",
      "Total Time: 2m 24s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
